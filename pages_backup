# pages/01_üìä_Explorar_Dados.py
import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime

@st.cache_data
def load_data():
    df = pd.read_csv("chicago_crimes.csv")
    # Converter coluna de datas
    df['Date'] = pd.to_datetime(df['Date'])
    return df

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="An√°lise Estat√≠stica - Crimes Chicago", page_icon="üìä", layout="wide")

# T√≠tulo e navega√ß√£o
st.title("An√°lise Estat√≠stica")
st.markdown("Navegue e filtre o banco de dados completo de crimes de Chicago")

# Bot√£o para voltar √† p√°gina inicial
if st.button("‚Üê Voltar para P√°gina Inicial"):
    st.switch_page("app.py")

# Carregar dados
df = load_data()

# Sidebar com os filtros dispon√≠veis
st.sidebar.header("üîß Filtros para An√°lise")

#### TIPOS DE FILTRO ####

# FILTRO TEMPORAL # 
anos = st.sidebar.multiselect(
    "Selecione os anos para an√°lise:",
    df['Year'].unique(),
    default=df['Year'].unique()
)

# FILTRO POR TIPO DE CRIME #
crime_types = df['Primary Type'].unique()
selected_crime = st.sidebar.multiselect("Selecione o tipo de crime:", crime_types, default=crime_types)

# Filtro por per√≠odo do dia
st.sidebar.subheader("Selecione o per√≠odo do dia:")

# dicion√°rio com os per√≠odos do dia #
periods = {
    "Madrugada (00:00-05:59)": (0, 5),
    "Manh√£ (06:00-11:59)": (6, 11),
    "Tarde (12:00-17:59)": (12, 17),
    "Noite (18:00-23:59)": (18, 23),
    "Todo o dia (00:00-23:59)": (0, 23)
}   

periodo_selecionado = st.sidebar.selectbox("Per√≠odo do dia:", options=list(periods.keys()))

# Filtro adicional por distrito 
if 'District' in df.columns:
    distritos = st.sidebar.multiselect(
        "Selecione os distritos:",
        df['District'].unique(),
        default=df['District'].unique()
    )

### APLICA√á√ÉO DOS FILTROS ###
df_filtrado = df.copy()

# Aplicar filtros sequencialmente
if anos:
    df_filtrado = df_filtrado[df_filtrado['Year'].isin(anos)]

if selected_crime:
    df_filtrado = df_filtrado[df_filtrado['Primary Type'].isin(selected_crime)]

if periodo_selecionado != "Todo o dia":
    hora_i, hora_f = periods[periodo_selecionado]
    df_filtrado = df_filtrado[
        (df_filtrado['Date'].dt.hour >= hora_i) & 
        (df_filtrado['Date'].dt.hour <= hora_f)
    ]

# Filtro de distrito 
if 'District' in df.columns and 'distritos' in locals():
    df_filtrado = df_filtrado[df_filtrado['District'].isin(distritos)]

### VALIDA√á√ÉO DE DADOS FILTRADOS ###
if df_filtrado.empty:
    st.warning("‚ö†Ô∏è Nenhum dado encontrado com os filtros selecionados. Tente ajustar os crit√©rios de filtragem.")
    
    # Mostrar dados originais se os filtros n√£o retornarem nada
    st.info("Mostrando dados sem filtros aplicados:")
    df_filtrado = df.copy()
else:
    st.success(f"‚úÖ **{len(df_filtrado):,} registros** encontrados com os filtros aplicados")

### Exibi√ß√£o quantitativa da an√°lise ###
st.header("üìà Vis√£o Geral dos Dados Selecionados")

# M√©tricas principais
col1, col2, col3, col4 = st.columns(4)

with col1:
    total_crimes = len(df_filtrado)
    st.metric("Total de crimes", f"{total_crimes:,}")

with col2:
    dias_unicos = df_filtrado['Date'].dt.date.nunique()
    if dias_unicos > 0:
        crimes_por_dia = total_crimes / dias_unicos
        st.metric("M√©dia de crimes por dia", f"{crimes_por_dia:.1f}")
    else:
        st.metric("M√©dia de crimes por dia", "0.0")

with col3:
    if 'Arrest' in df_filtrado.columns:
        taxa_arrest = (df_filtrado['Arrest'].mean() * 100)
        st.metric("Taxa de Pris√µes", f"{taxa_arrest:.1f}%")
    else:
        hora_pico = df_filtrado['Date'].dt.hour.mode()
        hora_pico = hora_pico.iloc[0] if not hora_pico.empty else "N/D"
        st.metric("Hor√°rio de Pico", f"{hora_pico}h")

with col4:
    if not df_filtrado.empty:
        principal_crime = df_filtrado['Primary Type'].value_counts().idxmax()
        st.metric("Tipo de crime mais comum", principal_crime)
    else:
        st.metric("Tipo de crime mais comum", "N/D")

### VISUALIZA√á√ïES GR√ÅFICAS ###
st.header("üìä An√°lises Visuais R√°pidas")

# Criar colunas para os gr√°ficos
col1, col2 = st.columns(2)

with col1:
    st.subheader("Distribui√ß√£o por Tipo de Crime")
    if not df_filtrado.empty:
        # Gr√°fico de pizza para tipos de crime
        crime_counts = df_filtrado['Primary Type'].value_counts().head(10)
        fig_pizza = px.pie(
            values=crime_counts.values,
            names=crime_counts.index,
            title="Top 10 Tipos de Crime"
        )
        st.plotly_chart(fig_pizza, width='stretch')
    else:
        st.info("Nenhum dado para exibir no gr√°fico.")

with col2:
    st.subheader("Crimes por Hora do Dia")
    if not df_filtrado.empty:
        # Gr√°fico de crimes por hora
        df_filtrado['Hora'] = df_filtrado['Date'].dt.hour
        crimes_por_hora = df_filtrado['Hora'].value_counts().sort_index()
        
        fig_hora = px.bar(
            x=crimes_por_hora.index,
            y=crimes_por_hora.values,
            title="Distribui√ß√£o de Crimes por Hora",
            labels={'x': 'Hora do Dia', 'y': 'N√∫mero de Crimes'}
        )
        st.plotly_chart(fig_hora, width='stretch')
    else:
        st.info("Nenhum dado para exibir no gr√°fico.")

### AN√ÅLISE DETALHADA ###
st.header("üîç An√°lise Detalhada dos Dados")

# Criar abas para diferentes an√°lises
tab1, tab2, tab3 = st.tabs(["üìã Dados Filtrados", "üìä Estat√≠sticas", "üì• Exportar Dados"])

with tab1:
    st.subheader("Visualiza√ß√£o dos Dados Filtrados")
    st.write(f"Mostrando {len(df_filtrado)} registros:")
    
    # Pagina√ß√£o simples
    page_size = 100
    total_pages = max(1, len(df_filtrado) // page_size)
    
    page = st.number_input("P√°gina", min_value=1, max_value=total_pages, value=1)
    start_idx = (page - 1) * page_size
    end_idx = start_idx + page_size
    
    st.dataframe(df_filtrado.iloc[start_idx:end_idx], width='stretch')
    
    st.write(f"P√°gina {page} de {total_pages} | Registros {start_idx+1} a {min(end_idx, len(df_filtrado))}")

with tab2:
    st.subheader("Estat√≠sticas Descritivas")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Distribui√ß√£o por Tipo de Crime:**")
        crime_percentages = df_filtrado['Primary Type'].value_counts(normalize=True) * 100
        for crime_type, percentage in crime_percentages.head(10).items():
            st.write(f"‚Ä¢ {crime_type}: **{percentage:.1f}%**")
        
        st.write("**Informa√ß√µes Gerais:**")
        st.write(f"‚Ä¢ Total de tipos distintos: **{df_filtrado['Primary Type'].nunique()}**")
        st.write(f"‚Ä¢ Per√≠odo coberto: **{dias_unicos} dias**")
    
    with col2:
        st.write("**Padr√µes Temporais:**")
        df_filtrado['Dia_Semana'] = df_filtrado['Date'].dt.day_name()
        dias_ordenados = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        crimes_dia = df_filtrado['Dia_Semana'].value_counts().reindex(dias_ordenados, fill_value=0)
        
        st.write("**Crimes por dia da semana:**")
        for dia, count in crimes_dia.items():
            st.write(f"‚Ä¢ {dia}: **{count}** crimes")

with tab3:
    st.subheader("Exportar Dados Filtrados")
    
    st.info("Exporte os dados filtrados para an√°lise externa")
    
    # Op√ß√µes de exporta√ß√£o
    col1, col2 = st.columns(2)
    
    with col1:
        # Download CSV
        csv = df_filtrado.to_csv(index=False)
        st.download_button(
            label="üì• Download como CSV",
            data=csv,
            file_name=f"chicago_crimes_filtrados_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
            mime="text/csv",
            use_container_width=True
        )
    
    with col2:
        # Estat√≠sticas do dataset
        st.write("**Resumo do Dataset:**")
        st.write(f"‚Ä¢ Registros: {len(df_filtrado):,}")
        st.write(f"‚Ä¢ Colunas: {len(df_filtrado.columns)}")
        st.write(f"‚Ä¢ Per√≠odo: {df_filtrado['Date'].min().strftime('%d/%m/%Y')} a {df_filtrado['Date'].max().strftime('%d/%m/%Y')}")

# Footer
st.markdown("---")
st.markdown("*M√≥dulo de Explora√ß√£o de Dados - Chicago Crime Analytics*")# 02_analise_estatistica.py - VERS√ÉO CORRIGIDA
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import datetime
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="An√°lise Explorat√≥ria - Crimes Chicago", 
    page_icon="üìà", 
    layout="wide"
)

# T√≠tulo e descri√ß√£o
st.title("An√°lise Explorat√≥ria dos Padr√µes de Crimes em Chicago")
st.markdown("""
### An√°lise Explorat√≥ria de S√©rie Temporal
Explore padr√µes temporais, sazonalidade e tend√™ncias dos crimes ao longo do tempo.
""")

# Carregar dados
@st.cache_data
def load_data():
    try:
        df = pd.read_csv("chicago_crimes.csv")
        if 'Date' in df.columns:
            df['Date'] = pd.to_datetime(df['Date'])
        return df
    except Exception as e:
        st.error(f"Erro ao carregar dados: {e}")
        return pd.DataFrame()

df = load_data()

if df.empty:
    st.warning("Nenhum dado carregado. Verifique o arquivo de dados.")
    st.stop()

# Sidebar para controles
st.sidebar.header("üéØ Controles de An√°lise")

# Filtros interativos
crime_types = sorted(df['Primary Type'].unique())
selected_crimes = st.sidebar.multiselect(
    "Tipos de Crime:",
    options=crime_types,
    default=['ASSAULT'] if 'ASSAULT' in crime_types else crime_types[:1]
)

available_years = sorted(df['Year'].unique())
selected_years = st.sidebar.multiselect(
    "Anos:",
    options=available_years,
    default=available_years
)

analysis_granularity = st.sidebar.radio(
    "Agrega√ß√£o Temporal:",
    ["Di√°ria", "Mensal", "Anual"],
    index=1
)

# Aplicar filtros
df_filtered = df[
    (df['Primary Type'].isin(selected_crimes)) & 
    (df['Year'].isin(selected_years))
].copy()

st.sidebar.info(f"üìä Registros filtrados: {len(df_filtered):,}")

# Fun√ß√£o para preparar dados temporais
def prepare_temporal_data(df, granularity):
    if granularity == "Di√°ria":
        freq = 'D'
    elif granularity == "Mensal":
        freq = 'M'
    else:
        freq = 'Y'
    
    temporal_data = df.resample(freq, on='Date').size().reset_index()
    temporal_data.columns = ['ds', 'y']
    return temporal_data

# Layout principal com tabs
tab1, tab2, tab3 = st.tabs(["üìä S√©rie Temporal", "üìà Estat√≠sticas", "üîç Padr√µes"])

with tab1:
    st.subheader("An√°lise da S√©rie Temporal")
    
    if df_filtered.empty:
        st.warning("Nenhum dado encontrado com os filtros selecionados.")
    else:
        temporal_data = prepare_temporal_data(df_filtered, analysis_granularity)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=temporal_data['ds'],
                y=temporal_data['y'],
                mode='lines+markers',
                name='Crimes',
                line=dict(color='#1f77b4', width=2)
            ))
            fig.update_layout(
                title=f'S√©rie Temporal - {", ".join(selected_crimes)}',
                xaxis_title='Data',
                yaxis_title=f'N√∫mero de Crimes ({analysis_granularity.lower()})',
                height=400
            )
            st.plotly_chart(fig, width='stretch')
        
        with col2:
            st.subheader("üìà M√©tricas")
            total_crimes = temporal_data['y'].sum()
            avg_crimes = temporal_data['y'].mean()
            max_crimes = temporal_data['y'].max()
            
            st.metric("Total de Crimes", f"{total_crimes:,}")
            st.metric(f"M√©dia {analysis_granularity}", f"{avg_crimes:.1f}")
            st.metric("M√°ximo", f"{max_crimes:,}")

with tab2:
    st.subheader("Estat√≠sticas Descritivas")
    
    if df_filtered.empty:
        st.warning("Nenhum dado encontrado com os filtros selecionados.")
    else:
        daily_data = prepare_temporal_data(df_filtered, "Di√°ria")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìã Estat√≠sticas B√°sicas")
            stats = {
                'M√©trica': ['Total', 'M√©dia', 'Mediana', 'Desvio Padr√£o', 'M√°ximo', 'M√≠nimo'],
                'Valor': [
                    f"{daily_data['y'].sum():,}",
                    f"{daily_data['y'].mean():.2f}",
                    f"{daily_data['y'].median():.2f}",
                    f"{daily_data['y'].std():.2f}",
                    f"{daily_data['y'].max():,}",
                    f"{daily_data['y'].min():,}"
                ]
            }
            stats_df = pd.DataFrame(stats)
            st.dataframe(stats_df, use_container_width=True, hide_index=True)
        
        with col2:
            st.subheader("üìä Distribui√ß√£o")
            fig_hist = px.histogram(
                daily_data, 
                x='y', 
                nbins=20,
                title='Distribui√ß√£o de Crimes por Dia',
                labels={'y': 'N√∫mero de Crimes'},
                color_discrete_sequence=['#1f77b4']
            )
            st.plotly_chart(fig_hist, width='stretch')

with tab3:
    st.subheader("An√°lise de Padr√µes")
    
    if df_filtered.empty:
        st.warning("Nenhum dado encontrado com os filtros selecionados.")
    else:
        daily_data = prepare_temporal_data(df_filtered, "Di√°ria")
        daily_data['dia_semana'] = daily_data['ds'].dt.day_name()
        daily_data['mes'] = daily_data['ds'].dt.month
        
        col1, col2 = st.columns(2)
        
        with col1:
            dias_ordenados = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
            media_semanal = daily_data.groupby('dia_semana')['y'].mean().reindex(dias_ordenados)
            
            fig_semanal = px.bar(
                x=media_semanal.index,
                y=media_semanal.values,
                title='M√©dia de Crimes por Dia da Semana',
                labels={'x': 'Dia da Semana', 'y': 'M√©dia de Crimes'}
            )
            st.plotly_chart(fig_semanal, width='stretch')
        
        with col2:
            media_mensal = daily_data.groupby('mes')['y'].mean()
            nomes_meses = ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 
                          'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dec']
            
            fig_mensal = px.line(
                x=nomes_meses,
                y=media_mensal.values,
                title='M√©dia de Crimes por M√™s',
                labels={'x': 'M√™s', 'y': 'M√©dia de Crimes'},
                markers=True
            )
            st.plotly_chart(fig_mensal, width='stretch')
        
        # SE√á√ÉO CORRIGIDA - An√°lise de Outliers
        st.subheader("üö® An√°lise de Valores At√≠picos")
        
        Q1 = daily_data['y'].quantile(0.25)
        Q3 = daily_data['y'].quantile(0.75)
        IQR = Q3 - Q1
        limite_superior = Q3 + 1.5 * IQR
        
        outliers = daily_data[daily_data['y'] > limite_superior]
        
        col3, col4 = st.columns(2)
        
        with col3:
            st.metric("Dias At√≠picos", len(outliers))
            st.metric("Limite Superior para Outliers", f"{limite_superior:.1f}")  # CORRIGIDO

        with col4:
            if len(outliers) > 0:
                st.markdown("**Top 5 Dias com Mais Crimes:**")
                top_dias = outliers.nlargest(5, 'y')[['ds', 'y']].copy()
                top_dias['ds'] = top_dias['ds'].dt.strftime('%Y-%m-%d')
                top_dias = top_dias.rename(columns={'ds': 'Data', 'y': 'Crimes'})  # CORRIGIDO
                st.dataframe(top_dias.reset_index(drop=True), width='stretch')
            else:
                st.info("Nenhum outlier detectado nos dados filtrados")

        # Distribui√ß√£o
        st.subheader("üìä Distribui√ß√£o de Frequ√™ncia")  # CORRIGIDO

        fig_dist = px.histogram(
            daily_data,
            x='y',
            nbins=30,
            title='Distribui√ß√£o de Crimes por Dia',
            labels={'y': 'N√∫mero de Crimes', 'count': 'Frequ√™ncia'},  # CORRIGIDO
            color_discrete_sequence=['#1f77b4']  # CORRIGIDO
        )

        st.plotly_chart(fig_dist, width='stretch')

# Recomenda√ß√µes para Modelagem
st.markdown("---")
st.subheader("üöÄ Recomenda√ß√µes para Modelagem Preditiva")  # CORRIGIDO

col1, col2, col3 = st.columns(3)

with col1:
    st.info("""
    **üìÖ Sazonalidade**
    - Padr√£o semanal bem definido
    - Considerar feriados
    - Sazonalidade mensal
    """)

with col2:
    st.info("""
    **‚öôÔ∏è Configura√ß√µes**
    - seasonality_mode='multiplicative'
    - weekly_seasonality=True
    - yearly_seasonality=True
    """)

with col3:
    st.info("""
    **üìä Valida√ß√£o**
    - Holdout temporal
    - M√©tricas: MAE, RMSE, MAPE
    - Cross-validation
    """)

# Rodap√©
st.markdown("---")
st.markdown("**Desenvolvido para An√°lise de Crimes de Chicago**")
    # 03_predicao_crimes.py - AMBOS MODELOS COM DADOS DI√ÅRIOS
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import holidays
from datetime import timedelta

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Predi√ß√£o Crimes", layout="wide")

# T√≠tulo e navega√ß√£o
st.title("üîÆ Predi√ß√£o Crimes")
if st.button("‚Üê Voltar ao In√≠cio"):
    st.switch_page("app.py")

# Carregar dados
@st.cache_data
def load_data():
    try:
        df = pd.read_csv("chicago_crimes.csv")
        if 'Date' in df.columns:
            df['Date'] = pd.to_datetime(df['Date'])
        return df
    except Exception as e:
        st.error(f"Erro ao carregar dados: {e}")
        return pd.DataFrame()

df = load_data()

if df.empty:
    st.warning("Dados n√£o carregados. Verifique o arquivo.")
    st.stop()

# Sidebar - Sele√ß√£o do modelo
st.sidebar.header("ü§ñ Escolha do Modelo")
modelo_selecionado = st.sidebar.radio(
    "Selecione o modelo:",
    ["Prophet", "Random Forest"],
    help="Ambos modelos usar√£o dados DI√ÅRIOS para compara√ß√£o justa"
)

# Filtros comuns
crime_types = sorted(df['Primary Type'].unique())
selected_crime = st.sidebar.selectbox(
    "Tipo de Crime", 
    crime_types,
    index=crime_types.index('ASSAULT') if 'ASSAULT' in crime_types else 0
)

available_years = sorted(df['Year'].unique())

# CONFIGURA√á√ïES PARA AMBOS OS MODELOS (DI√ÅRIOS) - CORRIGIDO
st.sidebar.header("üìÖ Configura√ß√µes Temporais")

# Ordenar anos dispon√≠veis
available_years_sorted = sorted(available_years)

# Selecionar intervalo de treino
if len(available_years_sorted) >= 2:
    train_start = st.sidebar.selectbox(
        "In√≠cio do Treino", 
        available_years_sorted[:-1],
        index=0
    )
    
    train_end = st.sidebar.selectbox(
        "Fim do Treino", 
        [y for y in available_years_sorted if y > train_start],
        index=0
    )
    
    train_years = list(range(train_start, train_end + 1))
    
    # Ano de teste (ap√≥s o treino)
    available_test_years = [y for y in available_years_sorted if y > train_end]
    test_year = st.sidebar.selectbox(
        "Ano para Teste", 
        available_test_years
    )
else:
    st.warning("N√£o h√° anos suficientes para treino e teste")
    st.stop()

# Configura√ß√µes espec√≠ficas por modelo
if modelo_selecionado == "Prophet":
    seasonality_mode = st.sidebar.radio("Modo Sazonalidade", ["multiplicative", "additive"])
    include_holidays = st.sidebar.checkbox("Incluir Feriados", value=True)

else:  # Random Forest
    st.sidebar.header("üîß Par√¢metros Random Forest")
    n_estimators = st.sidebar.slider("N√∫mero de √Årvores", 50, 500, 200)
    lags_dias = st.sidebar.slider("Lags (dias hist√≥ricos)", 7, 90, 30)
    include_weekends = st.sidebar.checkbox("Incluir Features de Fim de Semana", value=True)

# VERIFICA√á√ÉO DE SEGURAN√áA - CORRIGIDO
if not train_years or not test_year:
    st.info("Selecione anos para treino e teste para continuar.")
    st.stop()

# Verificar se h√° sobreposi√ß√£o de anos
anos_treino_set = set(train_years)
if test_year in anos_treino_set:
    st.error("‚ùå O ano de teste n√£o pode estar nos anos de treino!")
    st.stop()

# Verificar se h√° dados suficientes
df_filtered = df[(df['Primary Type'] == selected_crime) & 
                 (df['Year'].isin(train_years + [test_year]))]

if df_filtered.empty:
    st.error("‚ùå N√£o h√° dados para os anos selecionados!")
    st.stop()

st.sidebar.success(f"‚úÖ Dados carregados: {len(df_filtered)} registros")
st.sidebar.write(f"üìä Per√≠odo: {df_filtered['Date'].min().strftime('%Y-%m-%d')} a {df_filtered['Date'].max().strftime('%Y-%m-%d')}")

# FUN√á√ÉO CORRIGIDA: Preparar e dividir dados
def preparar_e_dividir_dados(df_filtrado, train_years, test_year):
    """Prepara dados di√°rios e divide corretamente"""
    dados_diarios = df_filtrado.resample('D', on='Date').size().reset_index()
    dados_diarios.columns = ['ds', 'y']
    
    # Usar o final do √∫ltimo ano de treino como corte
    ultimo_ano_treino = max(train_years)
    data_corte = f"{ultimo_ano_treino}-12-31"
    data_corte = pd.to_datetime(data_corte)
    
    dados_treino = dados_diarios[dados_diarios['ds'] <= data_corte]
    dados_teste = dados_diarios[dados_diarios['ds'] > data_corte]
    
    return dados_treino, dados_teste, data_corte

# PREPARAR DADOS DI√ÅRIOS (PARA AMBOS OS MODELOS) - CORRIGIDO
def preparar_dados_diarios(df_filtrado):
    """Prepara dados di√°rios para ambos os modelos"""
    dados_diarios = df_filtrado.resample('D', on='Date').size().reset_index()
    dados_diarios.columns = ['ds', 'y']
    return dados_diarios

# Bot√£o para executar previs√£o
if st.button(f"üöÄ Executar {modelo_selecionado} (Dados Di√°rios)", type="primary"):
    
    # Preparar dados (COMUM A AMBOS) - CORRIGIDO
    dados_treino, dados_teste, data_corte = preparar_e_dividir_dados(df_filtered, train_years, test_year)
    
    # Verificar se as divis√µes n√£o est√£o vazias
    if len(dados_treino) == 0:
        st.error("‚ùå Nenhum dado encontrado para o per√≠odo de treino!")
        st.stop()

    if len(dados_teste) == 0:
        st.error("‚ùå Nenhum dado encontrado para o per√≠odo de teste!")
        st.stop()
    
    st.write(f"üìÖ Dados Di√°rios - Treino: {len(dados_treino)} dias | Teste: {len(dados_teste)} dias")
    st.write(f"üìä Corte temporal: {data_corte.strftime('%Y-%m-%d')}")
    
    if modelo_selecionado == "Prophet":
        with st.spinner("Treinando modelo Prophet..."):
            try:
                from prophet import Prophet
                
                # Configurar o modelo Prophet
                model = Prophet(
                    seasonality_mode=seasonality_mode,
                    yearly_seasonality=True,
                    weekly_seasonality=True,
                    daily_seasonality=False
                )
                
                # Adicionar feriados se selecionado
                if include_holidays:
                    model.add_country_holidays(country_name='US')
                
                # Treinar o modelo
                model.fit(dados_treino)
                
                # Criar dataframe futuro para previs√£o
                future = model.make_future_dataframe(periods=len(dados_teste), freq='D')
                forecast = model.predict(future)
                
                # Combinar previs√µes com dados reais
                forecast_test = forecast[forecast['ds'] >= data_corte][['ds', 'yhat', 'yhat_lower', 'yhat_upper']]
                resultados = pd.merge(dados_teste, forecast_test, on='ds', how='left')
                
                # Calcular m√©tricas
                mape = mean_absolute_percentage_error(resultados['y'], resultados['yhat']) * 100
                mae = mean_absolute_error(resultados['y'], resultados['yhat'])
                mse = mean_squared_error(resultados['y'], resultados['yhat'])
                rmse = np.sqrt(mse)
                
                # Exibir m√©tricas
                st.success("‚úÖ Previs√£o Prophet conclu√≠da!")
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("MAPE", f"{mape:.2f}%")
                col2.metric("MAE", f"{mae:.2f}")
                col3.metric("MSE", f"{mse:.2f}")
                col4.metric("RMSE", f"{rmse:.2f}")
                
                # Gr√°fico comparativo
                st.subheader("üìä Compara√ß√£o: Previs√£o vs Real")
                
                fig = go.Figure()
                
                # Dados de treino
                fig.add_trace(go.Scatter(
                    x=dados_treino['ds'], y=dados_treino['y'],
                    mode='lines', name='Treino',
                    line=dict(color='blue', width=1),
                    opacity=0.7
                ))
                
                # Dados reais de teste
                fig.add_trace(go.Scatter(
                    x=resultados['ds'], y=resultados['y'],
                    mode='lines', name='Real (Teste)',
                    line=dict(color='green', width=2)
                ))
                
                # Previs√µes
                fig.add_trace(go.Scatter(
                    x=resultados['ds'], y=resultados['yhat'],
                    mode='lines', name=f'Prophet (MAPE: {mape:.1f}%)',
                    line=dict(color='red', width=2, dash='dash')
                ))
                
                # Intervalo de confian√ßa
                fig.add_trace(go.Scatter(
                    x=resultados['ds'], y=resultados['yhat_upper'],
                    mode='lines', name='Intervalo Superior',
                    line=dict(color='red', width=1, dash='dot'),
                    opacity=0.3
                ))
                
                fig.add_trace(go.Scatter(
                    x=resultados['ds'], y=resultados['yhat_lower'],
                    mode='lines', name='Intervalo Inferior',
                    line=dict(color='red', width=1, dash='dot'),
                    opacity=0.3,
                    fill='tonexty'
                ))
                
                fig.update_layout(
                    title=f'Previs√£o Di√°ria de {selected_crime} - Prophet ({test_year})',
                    xaxis_title='Data',
                    yaxis_title='N√∫mero de Crimes por Dia',
                    hovermode='x unified',
                    height=500
                )
                
                st.plotly_chart(fig, width='stretch')
                
                # Componentes do Prophet
                st.subheader("üîç Componentes do Modelo Prophet")
                
                try:
                    fig_components = model.plot_components(forecast)
                    st.pyplot(fig_components)
                except:
                    st.info("Visualiza√ß√£o de componentes n√£o dispon√≠vel para esta configura√ß√£o")
                
            except Exception as e:
                st.error(f"Erro no Prophet: {e}")
                
    else:  # RANDOM FOREST COM DADOS DI√ÅRIOS
        with st.spinner("Treinando Random Forest (dados di√°rios)..."):
            try:
                # 1. Preparar dados di√°rios para Random Forest
                df_rf = pd.concat([dados_treino, dados_teste]).set_index('ds')
                df_rf = df_rf.sort_index()

                # 2. Fun√ß√£o para criar features DI√ÅRIAS
                def criar_features_diarias_sklearn(df, lags_dias=30):
                    """Cria features temporais DI√ÅRIAS para scikit-learn"""
                    
                    df_features = df.copy()
                    
                    # Features b√°sicas de tempo DI√ÅRIAS
                    df_features['day_of_week'] = df_features.index.dayofweek
                    df_features['day_of_month'] = df_features.index.day
                    df_features['month'] = df_features.index.month
                    df_features['year'] = df_features.index.year
                    df_features['quarter'] = df_features.index.quarter
                    df_features['week_of_year'] = df_features.index.isocalendar().week
                    
                    # Fim de semana
                    df_features['is_weekend'] = (df_features.index.dayofweek >= 5).astype(int)
                    
                    # Feriados (agora di√°rios)
                    us_holidays = holidays.US()
                    df_features['is_holiday'] = [date in us_holidays for date in df_features.index]
                    df_features['is_holiday'] = df_features['is_holiday'].astype(int)
                    
                    # Esta√ß√µes do ano
                    def get_season(month):
                        if month in [12, 1, 2]: return 0  # Inverno
                        elif month in [3, 4, 5]: return 1  # Primavera
                        elif month in [6, 7, 8]: return 2  # Ver√£o
                        else: return 3  # Outono
                    
                    df_features['season'] = df_features.index.month.map(get_season)
                    
                    # Final de ano
                    df_features['is_year_end'] = df_features.index.month.isin([11, 12]).astype(int)
                    
                    # Lags DI√ÅRIOS
                    for lag in range(1, lags_dias + 1):
                        df_features[f'lag_{lag}d'] = df_features['y'].shift(lag)
                    
                    # M√©dias m√≥veis DI√ÅRIAS
                    df_features['rolling_mean_7d'] = df_features['y'].rolling(window=7).mean()
                    df_features['rolling_mean_30d'] = df_features['y'].rolling(window=30).mean()
                    
                    return df_features

                # Criar features di√°rias
                crimes_com_features = criar_features_diarias_sklearn(df_rf, lags_dias)
                
                # Remover linhas com NaN (devido aos lags)
                crimes_com_features = crimes_com_features.dropna()
                
                st.write(f"üìà Features di√°rias criadas: {len(crimes_com_features.columns) - 1} vari√°veis")

                # 3. Split treino/teste (j√° temos as datas)
                train = crimes_com_features[crimes_com_features.index <= data_corte]
                test = crimes_com_features[crimes_com_features.index > data_corte]

                if len(train) == 0 or len(test) == 0:
                    st.error("N√£o h√° dados suficientes para treino e teste com o per√≠odo selecionado.")
                    st.stop()

                st.write(f"üéØ Treino: {len(train)} dias | Teste: {len(test)} dias")

                # 4. Preparar features e target
                feature_columns = [col for col in crimes_com_features.columns if col != 'y']
                X_train = train[feature_columns]
                y_train = train['y']
                X_test = test[feature_columns]
                y_test = test['y']

                # 5. Normalizar features
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                # 6. Modelo Random Forest
                model_rf = RandomForestRegressor(
                    n_estimators=n_estimators,
                    random_state=42,
                    n_jobs=-1
                )

                model_rf.fit(X_train_scaled, y_train)

                # 7. Previs√µes
                y_pred = model_rf.predict(X_test_scaled)

                # 8. M√©tricas
                mape_rf = mean_absolute_percentage_error(y_test, y_pred) * 100
                mae_rf = mean_absolute_error(y_test, y_pred)
                mse_rf = mean_squared_error(y_test, y_pred)
                rmse_rf = np.sqrt(mse_rf)

                # Exibir m√©tricas
                st.success("‚úÖ Previs√£o Random Forest (Di√°ria) conclu√≠da!")
                
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("MAPE", f"{mape_rf:.2f}%")
                col2.metric("MAE", f"{mae_rf:.2f}")
                col3.metric("MSE", f"{mse_rf:.2f}")
                col4.metric("RMSE", f"{rmse_rf:.2f}")

                # 9. Gr√°fico comparativo DI√ÅRIO
                st.subheader("üìä Compara√ß√£o Di√°ria: Previs√£o vs Real")
                
                results_df = pd.DataFrame({
                    'Real': y_test,
                    'Previsao': y_pred
                }, index=y_test.index)

                fig = go.Figure()
                
                # Treino
                fig.add_trace(go.Scatter(
                    x=train.index, y=train['y'],
                    mode='lines', name='Treino',
                    line=dict(color='blue', width=1),
                    opacity=0.7
                ))
                
                # Teste Real
                fig.add_trace(go.Scatter(
                    x=results_df.index, y=results_df['Real'],
                    mode='lines', name='Real (Teste)',
                    line=dict(color='green', width=2)
                ))
                
                # Previs√£o
                fig.add_trace(go.Scatter(
                    x=results_df.index, y=results_df['Previsao'],
                    mode='lines', name=f'Random Forest (MAPE: {mape_rf:.1f}%)',
                    line=dict(color='red', width=2, dash='dash')
                ))
                
                fig.update_layout(
                    title=f'Previs√£o Di√°ria de {selected_crime} - Random Forest ({test_year})',
                    xaxis_title='Data',
                    yaxis_title='N√∫mero de Crimes por Dia',
                    hovermode='x unified',
                    height=500
                )
                
                st.plotly_chart(fig, width='stretch')

                # 10. Tabela de compara√ß√£o (amostra de 15 dias)
                st.subheader("üìà Amostra de Previs√µes Di√°rias")
                
                comparacao = pd.DataFrame({
                    'Data': results_df.index.strftime('%Y-%m-%d'),
                    'Real': results_df['Real'],
                    'Previsto': results_df['Previsao'],
                    'Erro_Absoluto': np.abs(results_df['Real'] - results_df['Previsao']),
                    'Erro_Percentual': (np.abs(results_df['Real'] - results_df['Previsao']) / results_df['Real']) * 100
                }).head(15)  # Mostrar apenas 15 primeiros dias

                st.dataframe(comparacao.round(2), width='stretch')

                # 11. Estat√≠sticas de performance
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Erro M√©dio Absoluto", f"{comparacao['Erro_Absoluto'].mean():.1f} crimes/dia")
                with col2:
                    st.metric("Melhor Dia", f"{comparacao.loc[comparacao['Erro_Percentual'].idxmin(), 'Data']} ({comparacao['Erro_Percentual'].min():.1f}%)")
                with col3:
                    st.metric("Desvio Padr√£o Erro", f"{comparacao['Erro_Absoluto'].std():.1f}")

                # 12. Import√¢ncia das Features (top 10)
                st.subheader("üîç Top 10 Features Mais Importantes")
                
                feature_importance = pd.DataFrame({
                    'feature': feature_columns,
                    'importance': model_rf.feature_importances_
                }).sort_values('importance', ascending=False).head(10)

                fig_importance = go.Figure()
                fig_importance.add_trace(go.Bar(
                    x=feature_importance['importance'],
                    y=feature_importance['feature'],
                    orientation='h'
                ))
                fig_importance.update_layout(
                    title='Top 10 Features Mais Importantes (Dados Di√°rios)',
                    xaxis_title='Import√¢ncia',
                    yaxis_title='Features',
                    height=400
                )
                st.plotly_chart(fig_importance, width='stretch')

            except Exception as e:
                st.error(f"Erro no Random Forest: {e}")

else:
    # Tela inicial - informa√ß√µes sobre os modelos
    st.markdown(f"""
    ### üìã Compara√ß√£o Justa: Ambos Modelos com Dados Di√°rios
    
    Agora **Prophet** e **Random Forest** usam a mesma granularidade temporal:
    
    - ‚úÖ **Dados di√°rios** para ambos os modelos
    - ‚úÖ **Mesmo per√≠odo** de treino e teste  
    - ‚úÖ **M√©tricas compar√°veis** (MAPE, MAE, RMSE)
    - ‚úÖ **Visualiza√ß√£o consistente**
    
    **Configura√ß√£o Temporal:**
    - Treino: {min(train_years)} a {max(train_years)}
    - Teste: {test_year}
    """)
    
    if modelo_selecionado == "Prophet":
        st.markdown("""
        **Prophet (Di√°rio):**
        - Sazonalidade autom√°tica di√°ria/semanal/anual
        - Feriados e eventos especiais
        - Ideal para padr√µes complexos e tend√™ncias
        """)
    else:
        st.markdown("""
        **Random Forest (Di√°rio):**
        - Features temporais di√°rias (dia da semana, feriados, etc.)
        - Lags hist√≥ricos em dias
        - M√©dias m√≥veis de 7 e 30 dias
        - Identifica padr√µes n√£o-lineares complexos
        """)
import streamlit as st
import pandas as pd
import numpy as np
import folium
from streamlit_folium import st_folium
from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt
import datetime

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="An√°lise Espacial - Crimes Chicago", 
    page_icon="üó∫Ô∏è", 
    layout="wide"
)

# T√≠tulo e descri√ß√£o
st.title("üó∫Ô∏è An√°lise Espacial de Crimes")
st.markdown("""
### Mapeamento Interativo e An√°lise Espacial
Explore a distribui√ß√£o geogr√°fica dos crimes, identifique hotspots e padr√µes espaciais.
""")

# Sidebar para controles
st.sidebar.header("üéØ Controles de An√°lise")

# Carregar dados
@st.cache_data
def load_data():
    # AJUSTE: Coloque o caminho real do seu arquivo
    try:
        df = pd.read_csv("chicago_crimes.csv")
        return df
    except:
        st.error("Erro ao carregar dados. Verifique o caminho do arquivo.")
        return pd.DataFrame()

df = load_data()

if df.empty:
    st.stop()

# Filtros interativos na sidebar
st.sidebar.subheader("üîç Filtros de Dados")

# Sele√ß√£o de tipos de crime
crime_types = sorted(df['Primary Type'].unique())
selected_crimes = st.sidebar.multiselect(
    "Tipos de Crime",
    options=crime_types,
    default=['ASSAULT']  # Valor padr√£o baseado no seu c√≥digo
)

# Sele√ß√£o de ano
available_years = sorted(df['Year'].unique())
selected_years = st.sidebar.multiselect(
    "Anos",
    options=available_years,
    default=[2020]  # Valor padr√£o
)

# Sele√ß√£o de meses
st.sidebar.subheader("üìÖ Per√≠odo de An√°lise")
start_month, end_month = st.sidebar.slider(
    "Meses (Jan=1, Dez=12)",
    min_value=1,
    max_value=12,
    value=(1, 6)  # Janeiro a Junho como padr√£o
)

# Configura√ß√µes de an√°lise
st.sidebar.subheader("‚öôÔ∏è Configura√ß√µes de An√°lise")

analysis_type = st.sidebar.radio(
    "Tipo de Visualiza√ß√£o:",
    ["Mapa de Calor", "Clusters DBSCAN", "Pontos Individuais", "An√°lise por Distrito"]
)

# Par√¢metros DBSCAN (apenas se for usar clusters)
if analysis_type == "Clusters DBSCAN":
    eps_value = st.sidebar.slider("EPS (Dist√¢ncia)", 0.01, 0.5, 0.1, 0.01)
    min_samples_value = st.sidebar.slider("M√≠nimo de Amostras", 5, 100, 50)
    use_sampling = st.sidebar.checkbox("Usar amostragem para performance", value=True)

# Aplicar filtros
df_filtered = df[
    (df['Primary Type'].isin(selected_crimes)) &
    (df['Year'].isin(selected_years)) &
    (df['Month'].between(start_month, end_month))
].copy()

st.sidebar.info(f"üìä **Dados filtrados:** {len(df_filtered):,} registros")

# Layout principal com tabs
tab1, tab2, tab3 = st.tabs(["üó∫Ô∏è Mapa Interativo", "üìà An√°lise por Distrito", "üîç An√°lise de Clusters"])

with tab1:
    st.subheader("Mapa Interativo de Crimes")
    
    if df_filtered.empty:
        st.warning("Nenhum dado encontrado com os filtros selecionados.")
    else:
        # Criar mapa base
        chicago_center = [41.8781, -87.6298]
        m = folium.Map(location=chicago_center, zoom_start=10)
        
        # Amostrar para performance se necess√°rio
        if len(df_filtered) > 5000:
            display_df = df_filtered.sample(n=5000, random_state=42)
            st.info(f"Mostrando 5.000 pontos de {len(df_filtered):,} totais para melhor performance")
        else:
            display_df = df_filtered
        
        # Adicionar pontos ao mapa baseado no tipo de an√°lise
        if analysis_type == "Mapa de Calor":
            from folium.plugins import HeatMap
            heat_data = [[row['Latitude'], row['Longitude']] for idx, row in display_df.iterrows() 
                        if pd.notna(row['Latitude']) and pd.notna(row['Longitude'])]
            HeatMap(heat_data).add_to(m)
            
        elif analysis_type == "Clusters DBSCAN":
            # Aplicar DBSCAN diretamente no mapa
            coords = display_df[['Latitude', 'Longitude']].dropna()
            if len(coords) > 0:
                dbscan = DBSCAN(eps=eps_value, min_samples=min_samples_value)
                clusters = dbscan.fit_predict(coords)
                
                # Cores para clusters
                colors = ['red', 'blue', 'green', 'purple', 'orange', 'darkred', 'lightred', 'darkblue']
                
                for idx, (_, row) in enumerate(coords.iterrows()):
                    color = colors[clusters[idx] % len(colors)] if clusters[idx] != -1 else 'gray'
                    folium.CircleMarker(
                        location=[row['Latitude'], row['Longitude']],
                        radius=3,
                        color=color,
                        fill=True,
                        popup=f"Cluster: {clusters[idx]}"
                    ).add_to(m)
        
        else:  # Pontos individuais ou an√°lise por distrito
            for idx, row in display_df.iterrows():
                if pd.notna(row['Latitude']) and pd.notna(row['Longitude']):
                    folium.CircleMarker(
                        location=[row['Latitude'], row['Longitude']],
                        radius=2,
                        color='red',
                        fill=True,
                        popup=f"Tipo: {row['Primary Type']}<br>Data: {row.get('Date', 'N/A')}"
                    ).add_to(m)
        
        # Exibir mapa
        st_folium(m, width=1200, height=600)

with tab2:
    st.subheader("An√°lise por Distrito")
    
    if df_filtered.empty:
        st.warning("Nenhum dado encontrado com os filtros selecionados.")
    else:
        # An√°lise por distrito (seu c√≥digo original adaptado)
        if 'District' in df_filtered.columns:
            crime_counts_by_district = df_filtered.groupby('District').size().sort_values(ascending=False)
            total_crimes = crime_counts_by_district.sum()
            crime_proportion_by_district = (crime_counts_by_district / total_crimes) * 100
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Total de Crimes", f"{total_crimes:,}")
                st.metric("Distritos com Ocorr√™ncias", len(crime_counts_by_district))
            
            with col2:
                st.metric(
                    "Per√≠odo Analisado", 
                    f"{datetime.date(selected_years[0], start_month, 1).strftime('%b/%Y')} - {datetime.date(selected_years[0], end_month, 1).strftime('%b/%Y')}"
                )
            
            # Tabelas
            st.subheader("üìã Estat√≠sticas por Distrito")
            
            col3, col4 = st.columns(2)
            
            with col3:
                st.markdown("**Contagem Absoluta (Top 20)**")
                st.dataframe(
                    crime_counts_by_district.head(20).reset_index().rename(
                        columns={'District': 'Distrito', 0: 'N¬∫ de Crimes'}
                    ),
                    use_container_width=True
                )
            
            with col4:
                st.markdown("**Propor√ß√£o (%) do Total (Top 20)**")
                proportion_df = crime_proportion_by_district.head(20).round(2).reset_index()
                proportion_df = proportion_df.rename(
                    columns={'District': 'Distrito', 0: 'Propor√ß√£o (%)'}
                )
                st.dataframe(proportion_df, width='stretch')
            
            # Gr√°fico
            st.subheader("üìä Distribui√ß√£o por Distrito")
            top_n_districts = min(20, len(crime_counts_by_district))
            
            fig, ax = plt.subplots(figsize=(12, 6))
            crime_counts_by_district.head(top_n_districts).plot(kind='bar', ax=ax, color='skyblue')
            ax.set_title(f'Crimes por Distrito (Top {top_n_districts})')
            ax.set_xlabel('Distrito')
            ax.set_ylabel('N√∫mero de Crimes')
            ax.tick_params(axis='x', rotation=45)
            plt.tight_layout()
            st.pyplot(fig)
            
        else:
            st.warning("Coluna 'District' n√£o encontrada nos dados.")

with tab3:
    st.subheader("An√°lise de Clusters com DBSCAN")
    
    if st.button("üîç Executar An√°lise de Clusters", type="primary"):
        with st.spinner("Processando clusters..."):
            # Preparar dados para DBSCAN
            coords = df_filtered[['Latitude', 'Longitude']].dropna()
            
            if coords.empty:
                st.error("N√£o h√° coordenadas v√°lidas para an√°lise.")
            else:
                # Amostragem para performance
                if use_sampling and len(coords) > 50000:
                    coords_sample = coords.sample(n=50000, random_state=42)
                    st.info(f"üìä Usando amostra de 50.000 pontos de {len(coords):,} totais")
                else:
                    coords_sample = coords
                
                # Normaliza√ß√£o
                coords_normalized = (coords_sample - coords_sample.mean()) / coords_sample.std()
                
                # Executar DBSCAN
                dbscan = DBSCAN(eps=eps_value, min_samples=min_samples_value, n_jobs=-1)
                clusters = dbscan.fit_predict(coords_normalized)
                
                # M√©tricas
                n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)
                n_noise = list(clusters).count(-1)
                noise_percentage = (n_noise / len(clusters)) * 100
                
                # Display metrics
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Clusters Identificados", n_clusters)
                with col2:
                    st.metric("Pontos de Ru√≠do", n_noise)
                with col3:
                    st.metric("Taxa de Ru√≠do", f"{noise_percentage:.1f}%")
                with col4:
                    st.metric("Pontos Analisados", len(coords_sample))
                
                # Gr√°fico de clusters
                st.subheader("üìà Visualiza√ß√£o dos Clusters")
                
                fig, ax = plt.subplots(figsize=(12, 8))
                scatter = ax.scatter(
                    coords_sample.iloc[:, 0], 
                    coords_sample.iloc[:, 1], 
                    c=clusters, 
                    cmap='tab10', 
                    s=10, 
                    alpha=0.6
                )
                ax.set_title(f'Clusters Espaciais - {n_clusters} clusters, {n_noise} ru√≠dos ({noise_percentage:.1f}%)')
                ax.set_xlabel('Longitude (normalizada)')
                ax.set_ylabel('Latitude (normalizada)')
                plt.colorbar(scatter, ax=ax, label='Cluster ID')
                plt.tight_layout()
                st.pyplot(fig)

# Rodap√© informativo
st.markdown("---")
st.markdown("""
**üí° Dicas de Uso:**

- **Mapa de Calor**: Ideal para identificar hotspots de criminalidade
- **Clusters DBSCAN**: Mostra agrupamentos naturais de ocorr√™ncias  
- **Pontos Individuais**: Permite an√°lise detalhada de cada crime
- **An√°lise por Distrito**: Compara a distribui√ß√£o entre regi√µes administrativas

**üìä Filtros Dispon√≠veis:** Tipo de crime, ano, meses, par√¢metros de clusteriza√ß√£o""")
